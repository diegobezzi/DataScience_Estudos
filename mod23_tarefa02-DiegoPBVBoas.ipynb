{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166f6f33-c507-4fc6-9ebd-9986eb51ea53",
   "metadata": {},
   "source": [
    "\n",
    "[![ebac_logo-data_science.png](https://raw.githubusercontent.com/diegobezzi/DataScience_Estudos/main/ebac-course-utils/media/logo/ebac_logo-data_science.png)](https://github.com//diegobezzi/DataScience_Estudos)\n",
    "<!-- <img src=\"https://raw.githubusercontent.com/diegobezzi/DataScience_Estudos/main/ebac-course-utils/media/logo/ebac_logo-data_science.png\" alt=\"ebac_logo-data_science\"> -->\n",
    "\n",
    "---\n",
    "\n",
    "<!-- # **Profissão: Cientista de Dados** -->\n",
    "### **Módulo 23** | Combinação de modelos I | Exercício 1\n",
    "\n",
    "**Aluno:** [Diego Perez Bezzi Vilas Boas](https://www.linkedin.com/in/diegobezzi/)<br>\n",
    "**Data:** 12 de junho de 2024.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6a816-ff6f-403b-8622-0ca33cea960b",
   "metadata": {},
   "source": [
    "# Tarefa 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01af968-8131-4047-936f-ee55315b09a4",
   "metadata": {},
   "source": [
    "**1.** Monte um passo a passo para o algoritmo RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cc51a-cdf8-44ae-b8d8-93ebce1009e1",
   "metadata": {},
   "source": [
    "> Semelhante ao *Bagging*, o ***Random Forest*** consiste nos seguintes passos:\n",
    "> 1. ***Bootstrap + Feature Selection:*** Assim como no *Bagging*, o *Random Forest* utiliza amostras aleatórias com reposição do conjunto de dados de treinamento original. No entanto, em cada uma dessas amostras, apenas um subconjunto aleatório de variáveis é selecionado (*feature selection*). No caso de problemas de classificação, geralmente é recomendado escolher a raiz quadrada do número total de variáveis, enquanto em problemas de regressão, um terço das variáveis é comumente usado.\n",
    "> 2. **Modelagem com árvores de decisão:** Nesta etapa, um modelo de *Machine Learning*, especificamente uma árvore de decisão, é treinado de forma independente em cada amostra *bootstrap* com as variáveis aleatórias que foram definidas no passo anterior.\n",
    "> 3. **Agregação:** Por fim, os resultados de cada modelo independente (cada árvore de decisão) são agregados para obter uma previsão final. Em problemas de classificação, a agregação é geralmente feita por meio do voto majoritário, em que a classe prevista com mais frequência pelos modelos individuais é selecionada como a classe final. Já em problemas de regressão, a agregação é realizada calculando a média das previsões dos modelos individuais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805122b5-5f98-4013-bac2-d36ed341325c",
   "metadata": {},
   "source": [
    "**2.** Explique com suas palavras o Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7b205-08c5-45a8-a29e-45e1c9baf2b5",
   "metadata": {},
   "source": [
    "> ***Random Forest*** pode ser definido como uma extensão do *Bootstrap Aggregating*, conhecido como *Bagging*, que oferece melhorias em desempenho e resultados. Assim como no *Bagging*, o *Random Forest* é um método de combinação de modelos de *Machine Learning*, em que cada modelo é treinado em variações do conjunto de dados original. Essas variações, chamadas de *amostras bootstrap*, consistem em subconjuntos aleatórios do conjunto de dados original, com possíveis repetições, mantendo o mesmo número de linhas. No entanto, o *Random Forest* diferencia-se ao utilizar apenas uma quantidade determinada e aleatória de variáveis em cada modelo, especificamente em modelos de árvore de decisão. Essa abordagem tem o objetivo de reduzir a variância dos resultados e atenuar o risco de *overfitting*. Para obter a previsão final, a agregação dos modelos é realizada de forma semelhante ao *Bagging*, onde a média é utilizada para regressão e votação para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54f311-a631-4d9c-a2e0-92064484db82",
   "metadata": {},
   "source": [
    "**3.** Qual a diferença entre Bagging e Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd86441-282d-434f-8a6c-c84f668a7a31",
   "metadata": {},
   "source": [
    "> A diferença entre *Bagging* e *Random Forest* está no desempenho e na redução da variância entre os resultados dos modelos. *Bagging* é uma técnica mais geral de combinação de modelos de *Machine Learning* utilizando amostragem aleatória, enquanto *Random Forest* é uma variação mais específica desse método que utiliza árvores de decisão. No *Random Forest*, cada modelo é treinado em subconjuntos aleatórios do conjunto de dados original, com uma quantidade reduzida e aleatória de variáveis consideradas em cada modelo. Essa abordagem aumenta a robustez do modelo e, ao combinar os resultados dos modelos, a previsão final tende a ser mais precisa do que no *Bagging*. Portanto, *Random Forest* é uma extensão aprimorada do *Bagging*, fornecendo um desempenho melhorado e uma redução adicional na variância dos resultados.\n",
    ">\n",
    ">> **\"*Random Forest* funciona melhor que o *Bagging*, pois as árvores amostradas são mais independentes (menor correlação).\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478db89-7ae8-4216-a600-9f5c97f3cbf0",
   "metadata": {},
   "source": [
    "**4.** (Opcional) Implementar em python o Random Forest\n",
    "> - Bootstrap\n",
    "> - Feature selection\n",
    "> - Modelagem com Decision trees\n",
    "> - Agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a698d4e7-cef9-411a-9227-f6a0ce9e5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import das bibliotecas:\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets        import load_wine\n",
    "from sklearn.datasets        import load_diabetes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.metrics         import accuracy_score\n",
    "\n",
    "from sklearn.tree            import DecisionTreeRegressor\n",
    "from sklearn.metrics         import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9eebb7d-9eda-475d-87f6-a8565dd80612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "Accuracy score: 0.9830508474576272\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_test  y_pred\n",
       "0        2       2\n",
       "1        1       1\n",
       "2        1       1\n",
       "3        1       1\n",
       "4        0       0\n",
       "5        0       0\n",
       "6        1       1\n",
       "7        2       2\n",
       "8        1       1\n",
       "9        1       1\n",
       "10       2       2\n",
       "11       0       0\n",
       "12       1       1\n",
       "13       2       2\n",
       "14       2       2\n",
       "15       2       2\n",
       "16       1       1\n",
       "17       2       2\n",
       "18       1       1\n",
       "19       0       0\n",
       "20       0       0\n",
       "21       1       1\n",
       "22       0       0\n",
       "23       0       0\n",
       "24       0       0\n",
       "25       1       1\n",
       "26       0       0\n",
       "27       0       0\n",
       "28       2       2\n",
       "29       0       0\n",
       "30       0       0\n",
       "31       1       1\n",
       "32       1       1\n",
       "33       1       1\n",
       "34       2       2\n",
       "35       0       0\n",
       "36       1       1\n",
       "37       1       1\n",
       "38       2       2\n",
       "39       2       2\n",
       "40       0       0\n",
       "41       0       0\n",
       "42       1       1\n",
       "43       0       0\n",
       "44       0       0\n",
       "45       1       1\n",
       "46       1       1\n",
       "47       2       2\n",
       "48       0       0\n",
       "49       1       1\n",
       "50       1       2\n",
       "51       1       1\n",
       "52       1       1\n",
       "53       1       1\n",
       "54       2       2\n",
       "55       0       0\n",
       "56       0       0\n",
       "57       2       2\n",
       "58       0       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de classificação:\n",
    "\n",
    "X = load_wine().data\n",
    "y = load_wine().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_wine().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_classifier(df:pd.DataFrame, \n",
    "                  num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                  test_size:float=0.25\n",
    "                 ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(np.sqrt(X_train.shape[1])),  # Cálculo da raiz quadrada da quantidade de variáveis\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "        \n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "    \n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mode(axis=1)  # Agregando o valor com maior número de aparições nas predições dos modelos\n",
    "                .rename(columns={0:'y_pred'}))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Accuracy score:', accuracy_score(y_true=y_test, \n",
    "                                            y_pred=y_pred['y_pred']\n",
    "                                           ))\n",
    "\n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred['y_pred'].astype(int)], \n",
    "                     axis=1)\n",
    "\n",
    "rf_classifier(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44692d5-b1a0-4351-af50-6941709045c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor()\n",
      "Mean squared error: 4134.850916894978\n",
      "Coefficient of determination: 0.29423659026602156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.0</td>\n",
       "      <td>138.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.0</td>\n",
       "      <td>142.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261.0</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>185.0</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>158.0</td>\n",
       "      <td>131.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>258.0</td>\n",
       "      <td>103.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>53.0</td>\n",
       "      <td>141.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>114.0</td>\n",
       "      <td>92.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0     141.0   138.7\n",
       "1      69.0   142.4\n",
       "2      88.0   174.0\n",
       "3      65.0    65.9\n",
       "4     261.0   239.0\n",
       "..      ...     ...\n",
       "141   185.0   213.0\n",
       "142   158.0   131.7\n",
       "143   258.0   103.3\n",
       "144    53.0   141.2\n",
       "145   114.0    92.9\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de regressão:\n",
    "\n",
    "X = load_diabetes().data\n",
    "y = load_diabetes().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_diabetes().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_regressor(df:pd.DataFrame, \n",
    "                 num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                 test_size:float=0.25\n",
    "                ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(X_train.shape[1]/3),  # Cálculo da quantidade de variáveis dividida por 3\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "\n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "\n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mean(axis=1)  # Agregando as predições dos modelos baseando n a média dos resultados\n",
    "                .rename('y_pred'))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Mean squared error:', mean_squared_error(y_true=y_test, \n",
    "                                                   y_pred=y_pred))\n",
    "    print('Coefficient of determination:', r2_score(y_true=y_test, \n",
    "                                                    y_pred=y_pred))\n",
    "    \n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred], \n",
    "                     axis=1)\n",
    "    \n",
    "rf_regressor(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afea5b5-6bed-4c12-adf1-988ce95e0db1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
